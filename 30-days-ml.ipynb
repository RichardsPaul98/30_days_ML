{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-07T06:43:15.878233Z","iopub.execute_input":"2021-10-07T06:43:15.878863Z","iopub.status.idle":"2021-10-07T06:43:15.894309Z","shell.execute_reply.started":"2021-10-07T06:43:15.878748Z","shell.execute_reply":"2021-10-07T06:43:15.893164Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:43:36.791151Z","iopub.execute_input":"2021-10-07T06:43:36.791576Z","iopub.status.idle":"2021-10-07T06:43:38.020549Z","shell.execute_reply.started":"2021-10-07T06:43:36.791539Z","shell.execute_reply":"2021-10-07T06:43:38.019331Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/30-days-of-ml/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/30-days-of-ml/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:43:42.118926Z","iopub.execute_input":"2021-10-07T06:43:42.119365Z","iopub.status.idle":"2021-10-07T06:43:46.988253Z","shell.execute_reply.started":"2021-10-07T06:43:42.119332Z","shell.execute_reply":"2021-10-07T06:43:46.987001Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:43:50.085954Z","iopub.execute_input":"2021-10-07T06:43:50.086306Z","iopub.status.idle":"2021-10-07T06:43:50.159772Z","shell.execute_reply.started":"2021-10-07T06:43:50.086278Z","shell.execute_reply":"2021-10-07T06:43:50.158568Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# List of categorical columns\nobject_cols = [col for col in features.columns if 'cat' in col]\n\n# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:43:53.124216Z","iopub.execute_input":"2021-10-07T06:43:53.124603Z","iopub.status.idle":"2021-10-07T06:43:57.287840Z","shell.execute_reply.started":"2021-10-07T06:43:53.124571Z","shell.execute_reply":"2021-10-07T06:43:57.286751Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# version 1\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:44:20.540241Z","iopub.execute_input":"2021-10-07T06:44:20.540760Z","iopub.status.idle":"2021-10-07T06:44:20.669055Z","shell.execute_reply.started":"2021-10-07T06:44:20.540727Z","shell.execute_reply":"2021-10-07T06:44:20.667905Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the model \nmodel = RandomForestRegressor(random_state=1)\n\n# Train the model (will take about 10 minutes to run)\nmodel.fit(X_train, y_train)\npreds_valid = model.predict(X_valid)\nprint(mean_squared_error(y_valid, preds_valid, squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:44:23.007728Z","iopub.execute_input":"2021-10-07T06:44:23.008190Z","iopub.status.idle":"2021-10-07T06:55:03.331769Z","shell.execute_reply.started":"2021-10-07T06:44:23.008153Z","shell.execute_reply":"2021-10-07T06:55:03.330997Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Use the model to generate predictions\npredictions = model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:25:57.241922Z","iopub.execute_input":"2021-08-24T08:25:57.242539Z","iopub.status.idle":"2021-08-24T08:26:14.140531Z","shell.execute_reply.started":"2021-08-24T08:25:57.242488Z","shell.execute_reply":"2021-08-24T08:26:14.139443Z"},"trusted":true},"execution_count":null,"outputs":[]}]}